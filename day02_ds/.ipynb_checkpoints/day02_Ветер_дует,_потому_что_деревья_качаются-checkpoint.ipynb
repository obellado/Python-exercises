{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from datetime import datetime, timedelta, date, time\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pylab\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сброс ограничений на число выводимых столбцов\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Деревья решений\n",
    "\n",
    "Огромное преимущество деревьев решений в том, что они легко интерпретируемы, понятны человеку.\n",
    "\n",
    "В основе популярных алгоритмов построения дерева решений лежит принцип жадной максимизации прироста информации – на каждом шаге выбирается тот признак, при разделении по которому прирост информации оказывается наибольшим. Дальше процедура повторяется рекурсивно, пока энтропия не окажется равной нулю или какой-то малой величине (если дерево не подгоняется идеально под обучающую выборку во избежание переобучения). \n",
    "\n",
    "Плюсы дерева решений:\n",
    "\n",
    "- Порождение четких правил классификации, понятных человеку, например, \"если возраст < 25 и интерес к мотоциклам, то отказать в кредите\". Это свойство называют интерпретируемостью модели;\n",
    "- Деревья решений могут легко визуализироваться, как сама модель (дерево), так и прогноз для отдельного взятого тестового объекта (путь в дереве);\n",
    "- Быстрые процессы обучения и прогнозирования;\n",
    "- Малое число параметров модели;\n",
    "- Поддержка и числовых, и категориальных признаков.\n",
    "\n",
    "Минусы:\n",
    "\n",
    "- У порождения четких правил классификации есть и другая сторона: деревья очень чувствительны к шумам во входных данных, вся модель может кардинально измениться, если немного изменится обучающая выборка (например, если убрать один из признаков или добавить несколько объектов), поэтому и правила классификации могут сильно изменяться, что ухудшает интерпретируемость модели;\n",
    "- Разделяющая граница, построенная деревом решений, имеет свои ограничения (состоит из гиперплоскостей, перпендикулярных какой-то из координатной оси), и на практике дерево решений по качеству классификации уступает некоторым другим методам.\n",
    "\n",
    "Рассмотрим пример построения дерева решений на данных о разновидностях цветка ириса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_excel('iris.xlsx')\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(iris, hue=\"species\", height=3)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"petal_length\", y=\"petal_width\", data=iris, height=12)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from IPython.core.display import Image, display\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.species\n",
    "X = iris.drop('species', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=21)\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "tree = DecisionTreeClassifier(random_state=21,max_depth=3)\n",
    "tree.fit(X_train_std, y_train)\n",
    "y_pred = tree.predict(X_test_std)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(tree, feature_names=X.columns , out_file='tree.dot', filled=True)\n",
    "!dot -Tpng 'tree.dot' -o 'tree.png'\n",
    "display(Image('tree.png', unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод ближайших соседей\n",
    "\n",
    "Метод ближайших соседей (k Nearest Neighbors, или kNN) — популярный метод классификации. На уровне интуиции суть метода такова: посмотри на соседей, какие преобладают, таков и ты. Формально основой метода является гипотеза компактности: если метрика расстояния между примерами введена достаточно удачно, то схожие примеры гораздо чаще лежат в одном классе, чем в разных.\n",
    "\n",
    "Для классификации каждого из объектов тестовой выборки необходимо последовательно выполнить следующие операции:\n",
    "\n",
    "Вычислить расстояние до каждого из объектов обучающей выборки\n",
    "Отобрать k объектов обучающей выборки, расстояние до которых минимально\n",
    "Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди k ближайших соседей\n",
    "\n",
    "Качество классификации методом ближайших соседей зависит от нескольких параметров:\n",
    "\n",
    "- число соседей;\n",
    "- метрика расстояния между объектами (часто используются метрика Хэмминга, евклидово расстояние, косинусное расстояние и расстояние Минковского). При использовании большинства метрик значения признаков надо масштабировать. \n",
    "- веса соседей (соседи тестового примера могут входить с разными весами, например, чем дальше пример, тем с меньшим коэффициентом учитывается его \"голос\")\n",
    "\n",
    "Плюсы метода ближайших соседей:\n",
    "\n",
    "- Простая реализация;\n",
    "- Неплохо изучен теоретически;\n",
    "- Как правило, метод хорош для первого решения задачи;\n",
    "- Можно адаптировать под нужную задачу выбором метрики или ядра (ядро может задавать операцию сходства для сложных объектов типа графов, а сам подход kNN остается тем же);\n",
    "- Неплохая интерпретация, можно объяснить, почему тестовый пример был классифицирован именно так.\n",
    "\n",
    "Минусы:\n",
    "\n",
    "- Метод считается быстрым в сравнении, например, с композициями алгоритмов, но в реальных задачах, как правило, число соседей, используемых для классификации, будет большим (100-150), и в таком случае алгоритм будет работать не так быстро, как дерево решений;\n",
    "- Если в наборе данных много признаков, то трудно подобрать подходящие веса и определить, какие признаки не важны для классификации;\n",
    "- Зависимость от выбранной метрики расстояния между примерами. Выбор по умолчанию евклидового расстояния чаще всего ничем не обоснован. Можно отыскать хорошее решение перебором параметров, но для большого набора данных это отнимает много времени;\n",
    "- Нет теоретических оснований выбора определенного числа соседей — только перебор (впрочем, чаще всего это верно для всех гиперпараметров всех моделей). В случае малого числа соседей метод чувствителен к выбросам, то есть склонен переобучаться;\n",
    "- Как правило, плохо работает, когда признаков много, из-за \"проклятия размерности\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_std, y_train)\n",
    "y_pred = knn.predict(X_test_std)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "\n",
    "В файлах *iCafe 2 month.xlsx* и *iCafe 15 days.xlsx* содержатся данные для обучения и тестирования классификаторов. Требуется построить три классификатора:\n",
    "\n",
    "- На основе линейной регрессии;\n",
    "- На основе дерева решений;\n",
    "- На основе метода ближайшего соседа.\n",
    "\n",
    "Основная цель - это достичь значение $F_1$ метрики на выборке 15 дней не менее чем:\n",
    "- 0.86 для логистической регрессии;\n",
    "- 0.9 для дерева решений;\n",
    "- 0.89 для метода ближайшего соседа.\n",
    "\n",
    "Вам будут даны небольшие подсказки в виде преобразования данных, но основные действия по преобразованию и выбора признаков для обучения остаются за вами.\n",
    "\n",
    "Так же, необходимо провести анализ и сделать выводы о результатах, при изменении параметров:\n",
    "- ***max_depth***, при обучении дерева решений;\n",
    "- ***n_neighbors***, при обучении классификатора методом ближайшего соседа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Получение данных для обучения (2 месяца) и тестовых данных (15 дней)\"\"\"\n",
    "df = pd.read_excel('iCafe 2 month.xlsx')\n",
    "df_15 = pd.read_excel('iCafe 15 days.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"просмотр df\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"просмотр df_15\"\n",
    "df_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просмотр данных указывает нам на две проблемы:\n",
    "\n",
    "1. Столбец *Order_date_time* содержит одновременно информацию о дате и времени. Для удобства последующего анализа нам необходимо разделить данные столбца на столбец даты и столбец времени.\n",
    "2. В *df_15* повились значения **NaN** (сокращение от Not a Number) — это специальное значение с плавающей точкой, распознаваемое всеми системами, которые используют стандартное представление IEEE с плавающей точкой. Это означает, что данные отсутствуют. Для дальнейшего анализа нам необходимо каким-либо образом обработать отсутствующие значения (либо удалить строки, либо заполнить значениями).\n",
    "\n",
    "Решим первую проблему:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Разбиение даты и времени на отдельные столбцы\"\"\"\n",
    "def share_date_time(df, sep = ' '):\n",
    "    X = df.Order_date_time.str.split(pat = sep, expand = True)\n",
    "    df['Order_date'], df['Order_time'] = X[0], X[1]\n",
    "    return df\n",
    "\n",
    "df = share_date_time(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15 = share_date_time(df_15)\n",
    "df_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь займемся решением второй проблемы. Для начала посмотрим информацию от том, как заполнены столбцы датафреймов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных для обучения пропусков нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В тестовых данных пропуски содержатся только в столбце Rain. Показать часть датафрейма с пропусками в столбце можно так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15[pd.isnull(df_15.Rain)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, на какие даты приходятся пропуски:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15.Order_date[pd.isnull(df_15.Rain)].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что три последних дня тестового датасета не имеют информации о дожде. Для того, чтобы заполнить отсутствующие данные, вам потребуется дополнительная информация: \n",
    "1. Определение дня недели\n",
    "2. Выявление влияния дождя на количество заказов по дням недели:\n",
    "    - Визуальный анализ распределения заказов по дням недели;\n",
    "    - Табличный анализ заказов по дням недели при наличии и отсутствии дождя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Определение дня недели, 1 - понедельник\"\"\"\n",
    "def day_of_the_week(df):\n",
    "    df['day_of_the_week'] = [datetime.isoweekday(datetime.strptime(j, '%Y-%m-%d %H:%M:%S')) \n",
    "                             for j in df.Order_date_time]\n",
    "    return df\n",
    "\n",
    "df = day_of_the_week(df)\n",
    "df_15 = day_of_the_week(df_15)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Преобразование времени заказа в секунды требуется для построения графиков (и для классификаторов)\"\"\"\n",
    "def time_to_sec(df):\n",
    "    df['Order_time_sec'] = pd.to_timedelta(df.Order_time)//np.timedelta64(1,'s')\n",
    "    return df\n",
    "\n",
    "df = time_to_sec(df)\n",
    "df_15 = time_to_sec(df_15)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Графики распределения заказов по дням недели\"\"\"\n",
    "weekday = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "for i, j in enumerate(weekday):\n",
    "    dff = df[df.day_of_the_week == i+1]\n",
    "    plt.scatter(dff.Order_time_sec[dff.Office == 1], dff.Delivery_time[dff.Office == 1], \n",
    "                marker = '.', color = 'red')\n",
    "    plt.scatter(dff.Order_time_sec[dff.Office == 0], dff.Delivery_time[dff.Office == 0], marker = '.')\n",
    "    plt.title(j)\n",
    "    plt.legend(['В офис', 'На дом'])\n",
    "    plt.xlabel('Время поступления заказа (Order_time_sec)')\n",
    "    plt.ylabel('Время доставки заказа (Delivery_time)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуальный анализ не сильно помог, разве что мы наблюдаем снижение количества заказов из офиса в субботу и воскресенье.\n",
    "\n",
    "Построим таблицу с аналитической информацией. Для каждого дня мы хотим получить аналитическую информацию об общем количестве заказов, количестве заказов в офис и количестве заказов на дом. Информация будет о среднем, максимальном и минимальном количестве заказов при условии наличия и отсутствия дождя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Формирование названий строк и столбцов таблицы\"\"\"\n",
    "\n",
    "mltindex = pd.DataFrame(columns = [['Monday', 'Monday', 'Monday', 'Tuesday', 'Tuesday', 'Tuesday', 'Wednesday', \n",
    "                                     'Wednesday', 'Wednesday', 'Thursday', 'Thursday', 'Thursday', 'Friday', \n",
    "                                     'Friday', 'Friday', 'Saturday', 'Saturday', 'Saturday', 'Sunday', 'Sunday', \n",
    "                                     'Sunday'], ['total', 'to_office', 'to_home']*7],\n",
    "                          index = [['rain', 'rain', 'rain', 'no_rain', 'no_rain', 'no_rain'],\n",
    "                                   ['mean_order', 'max_order', 'min_order']*2])\n",
    "mltindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Заполнение таблицы значениями\"\"\"\n",
    "\n",
    "def mean_max_min(df):\n",
    "    s = []\n",
    "    for j in df.Order_date.unique():\n",
    "        s.append(len(df[df.Order_date == j]))\n",
    "    if len(s) == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    return int(round(sum(s)/len(s),0)), max(s), min(s)\n",
    "\n",
    "def analysis(df, col):\n",
    "    weekday = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    df_day = df[df.day_of_the_week == weekday.index(col[0])+1]\n",
    "    if col[1] == 'to_office':\n",
    "        df_day = df_day[df_day.Office == 1]\n",
    "    elif col[1] == 'to_home':\n",
    "        df_day = df_day[df_day.Office == 0]\n",
    "    c = []\n",
    "    c.extend(mean_max_min(df_day[df_day.Rain == 1]))\n",
    "    c.extend(mean_max_min(df_day[df_day.Rain == 0]))\n",
    "    return c\n",
    "    \n",
    "for j in mltindex.columns:\n",
    "    mltindex[j] = analysis(df, j)\n",
    "    \n",
    "mltindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализировав полученную таблицу вы сможете заполнить пропущенные значения в тестовом датасете.\n",
    "\n",
    "\n",
    "Визуальный анализ показал, что день недели может повлиять на классификацию заказа. В текущем представлении данные о дне недели нельзя использовать при обучении классификатора. Их можно преобразовать так же как и время через синус и косинус, а можно создать столбцы дней недели и проставить нули и единицы, свидетельствующие о принадлежности заказа к соответствующему дню недели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Преобразование дня недели\"\"\"\n",
    "def day_to_day(df):\n",
    "    for i,j in enumerate(weekday):\n",
    "        df[j] = [1 if d == i+1 else 0 for d in df.day_of_the_week]\n",
    "    return df\n",
    "\n",
    "df = day_to_day(df)\n",
    "df_15 = day_to_day(df_15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
